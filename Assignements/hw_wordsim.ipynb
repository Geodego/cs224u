








<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Jupyter Notebook Viewer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">
  
  <meta name="robots" content="noindex,nofollow">
  

  <!--NEW RELIC Start Perf Measurement-->
  
  <!--NREND-->

  <!-- Le styles -->
  <link href="/static/build/styles.css" rel="stylesheet">

  <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <!-- Le fav and touch icons -->
  <link rel="shortcut icon" href="/static/ico/ipynb_icon_16x16.png">
  <link rel="apple-touch-icon-precomposed" sizes="144x144"
        href="/static/ico/apple-touch-icon-144-precomposed.png">
  <link rel="apple-touch-icon-precomposed" sizes="114x114"
        href="/static/ico/apple-touch-icon-114-precomposed.png">
  <link rel="apple-touch-icon-precomposed" sizes="72x72"
        href="/static/ico/apple-touch-icon-72-precomposed.png">
  <link rel="apple-touch-icon-precomposed"
        href="/static/ico/apple-touch-icon-57-precomposed.png">
  
  

  

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Notebook on nbviewer">
  <meta name="twitter:description" content="Check out this Jupyter notebook!">

  
  <meta name="twitter:domain" content="nbviewer.jupyter.org">
  <meta name="twitter:image:src" content="http://ipython.org/ipython-doc/dev/_images/ipynb_icon_128x128.png">

  
    <link href="/static/build/notebook.css" rel="stylesheet">
  

  

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML" type="text/javascript">
    </script>
    <script type="text/javascript">
      init_mathjax = function() {
        if (window.MathJax) {
          // MathJax loaded
          MathJax.Hub.Config({
            TeX: {
              equationNumbers: {
                autoNumber: "AMS",
                useLabelIds: true
              }
            },
            tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"] ],
              displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
              processEscapes: true,
              processEnvironments: true
            },
            displayAlign: 'center',
            "HTML-CSS": {
              styles: {'.MathJax_Display': {"margin": 0}},
              linebreaks: { automatic: true }
            }
          });
          MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
      }
      init_mathjax();
    </script>
  

  
    <script>
      (function() {
        function addWidgetsRenderer() {
          var mimeElement = document.querySelector('script[type="application/vnd.jupyter.widget-view+json"]');
          var scriptElement = document.createElement('script');
          var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';
          var widgetState;

          try {
            widgetState = mimeElement && JSON.parse(mimeElement.innerHTML);

            if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) {
              widgetRendererSrc = 'https://unpkg.com/jupyter-js-widgets@*/dist/embed.js';
            }
          } catch(e) {}

          scriptElement.src = widgetRendererSrc;
          document.body.appendChild(scriptElement);
        }

        document.addEventListener('DOMContentLoaded', addWidgetsRenderer);
      }());
    </script>
  

</head>

<body class="nbviewer">

  <!-- These are loaded at the top of the body so they are available to
       notebook cells when they are loaded below. -->
  <script src="/static/components/jquery/dist/jquery.min.js"></script>
  <script src="/static/components/requirejs/require.js"></script>
  <script src="/static/components/moment/min/moment.min.js"></script>
<!-- Navbar
================================================== -->
  <nav id="menubar" class="navbar navbar-default navbar-fixed-top" data-spy="affix">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="sr-only">Toggle navigation</span>
          <i class="fa fa-bars"></i>
        </button>
        <a class="navbar-brand" href="/">
          <img src="/static/img/nav_logo.svg" width="159"/>
        </a>
      </div>

      <div class="collapse navbar-collapse">
        <ul class="nav navbar-nav navbar-right">
          <li>
            <a class="active" href="https://jupyter.org">JUPYTER</a>
          </li>
          <li>
    <a href="/faq" title="FAQ" >
      
        <span>FAQ</span>
      
    </a>
  </li>

          
  
    
  
    
      
        <li>
    <a href="script/github/cgpotts/cs224u/blob/master/hw_wordsim.ipynb" title="View as Code" >
      <span class="fa fa-code fa-2x menu-icon"></span>
      <span class="menu-text">View as Code</span>
    </a>
  </li>
      
    
  

  
    <li>
    <a href="#" title="Python 3 Kernel" >
      <span class="fa fa-server fa-2x menu-icon"></span>
      <span class="menu-text">Python 3 Kernel</span>
    </a>
  </li>
  

  
    <li>
    <a href="https://github.com/cgpotts/cs224u/blob/master/hw_wordsim.ipynb" title="View on GitHub" >
      <span class="fa fa-github fa-2x menu-icon"></span>
      <span class="menu-text">View on GitHub</span>
    </a>
  </li>
  

  
    <li>
    <a href="https://mybinder.org/v2/gh/cgpotts/cs224u/master?filepath=hw_wordsim.ipynb" title="Execute on Binder" >
      <span class="fa fa-icon-binder fa-2x menu-icon"></span>
      <span class="menu-text">Execute on Binder</span>
    </a>
  </li>
  

  <li>
    <a href="https://raw.githubusercontent.com/cgpotts/cs224u/master/hw_wordsim.ipynb" title="Download Notebook" download>
      <span class="fa fa-download fa-2x menu-icon"></span>
      <span class="menu-text">Download Notebook</span>
    </a>
  </li>

        </ul>
      </div><!-- /.navbar-collapse -->
      
      
    </div>
  </nav>

  <div class="container container-main">
    
  
  <ol class="breadcrumb">
    
      <li>
        <a href="/github/cgpotts/cs224u/tree/master">cs224u</a>
      </li>
    
      <li>
        <a href="/github/cgpotts/cs224u/tree/master/hw_wordsim.ipynb">hw_wordsim.ipynb</a>
      </li>
    
  </ol>
  
  <div id="notebook">
    <div id="notebook-container">
      <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Homework-and-bake-off:-Word-similarity">Homework and bake-off: Word similarity<a class="anchor-link" href="#Homework-and-bake-off:-Word-similarity">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">__author__</span> <span class="o">=</span> <span class="s2">&quot;Christopher Potts&quot;</span>
<span class="n">__version__</span> <span class="o">=</span> <span class="s2">&quot;CS224u, Stanford, Fall 2020&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Contents">Contents<a class="anchor-link" href="#Contents">&#182;</a></h2><ol>
<li><a href="#Overview">Overview</a></li>
<li><a href="#Set-up">Set-up</a></li>
<li><a href="#Dataset-readers">Dataset readers</a></li>
<li><a href="#Dataset-comparisons">Dataset comparisons</a><ol>
<li><a href="#Vocab-overlap">Vocab overlap</a></li>
<li><a href="#Pair-overlap-and-score-correlations">Pair overlap and score correlations</a></li>
</ol>
</li>
<li><a href="#Evaluation">Evaluation</a><ol>
<li><a href="#Dataset-evaluation">Dataset evaluation</a></li>
<li><a href="#Dataset-error-analysis">Dataset error analysis</a></li>
<li><a href="#Full-evaluation">Full evaluation</a></li>
</ol>
</li>
<li><a href="#Homework-questions">Homework questions</a><ol>
<li><a href="#PPMI-as-a-baseline-[0.5-points]">PPMI as a baseline [0.5 points]</a></li>
<li><a href="#Gigaword-with-LSA-at-different-dimensions-[0.5-points]">Gigaword with LSA at different dimensions [0.5 points]</a></li>
<li><a href="#Gigaword-with-GloVe-[0.5-points]">Gigaword with GloVe [0.5 points]</a></li>
<li><a href="#Dice-coefficient-[0.5-points]">Dice coefficient [0.5 points]</a></li>
<li><a href="#t-test-reweighting-[2-points]">t-test reweighting [2 points]</a></li>
<li><a href="#Enriching-a-VSM-with-subword-information-[2-points]">Enriching a VSM with subword information [2 points]</a></li>
<li><a href="#Your-original-system-[3-points]">Your original system [3 points]</a></li>
</ol>
</li>
<li><a href="#Bake-off-[1-point]">Bake-off [1 point]</a></li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Overview">Overview<a class="anchor-link" href="#Overview">&#182;</a></h2><p>Word similarity datasets have long been used to evaluate distributed representations. This notebook provides basic code for conducting such analyses with a number of datasets:</p>
<table>
<thead><tr>
<th>Dataset</th>
<th>Pairs</th>
<th>Task-type</th>
<th>Current best Spearman $\rho$</th>
<th>Best $\rho$ paper</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://www.gabrilovich.com/resources/data/wordsim353/">WordSim-353</a></td>
<td>353</td>
<td>Relatedness</td>
<td>82.8</td>
<td><a href="https://arxiv.org/abs/1612.03975">Speer et al. 2017</a></td>
</tr>
<tr>
<td><a href="http://www2.mta.ac.il/~gideon/mturk771.html">MTurk-771</a></td>
<td>771</td>
<td>Relatedness</td>
<td>81.0</td>
<td><a href="https://arxiv.org/abs/1612.03975">Speer et al. 2017</a></td>
</tr>
<tr>
<td><a href="https://staff.fnwi.uva.nl/e.bruni/MEN">The MEN Test Collection</a></td>
<td>3,000</td>
<td>Relatedness</td>
<td>86.6</td>
<td><a href="https://arxiv.org/abs/1612.03975">Speer et al. 2017</a></td>
</tr>
<tr>
<td><a href="https://www.aclweb.org/anthology/D16-1235/">SimVerb-3500-dev</a></td>
<td>500</td>
<td>Similarity</td>
<td>61.1</td>
<td><a href="https://arxiv.org/pdf/1603.00892.pdf">Mrki&scaron;&cacute; et al. 2016</a></td>
</tr>
<tr>
<td><a href="https://www.aclweb.org/anthology/D16-1235/">SimVerb-3500-test</a></td>
<td>3,000</td>
<td>Similarity</td>
<td>62.4</td>
<td><a href="https://arxiv.org/pdf/1603.00892.pdf">Mrki&scaron;&cacute; et al. 2016</a></td>
</tr>
</tbody>
</table>
<p>Each of the similarity datasets contains word pairs with an associated human-annotated similarity score. (We convert these to distances to align intuitively with our distance measure functions.) The evaluation code measures the distance between the word pairs in your chosen VSM (which should be a <code>pd.DataFrame</code>).</p>
<p>The evaluation metric for each dataset is the <a href="https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient">Spearman correlation coefficient $\rho$</a> between the annotated scores and your distances, as is standard in the literature. We also macro-average these correlations across the datasets for an overall summary. (In using the macro-average, we are saying that we care about all the datasets equally, even though they vary in size.)</p>
<p>This homework (<a href="#Homework-questions">questions at the bottom of this notebook</a>) asks you to write code that uses the count matrices in <code>data/vsmdata</code> to create and evaluate some baseline models as well as an original model $M$ that you design. This accounts for 9 of the 10 points for this assignment.</p>
<p>For the associated bake-off, we will distribute two new word similarity or relatedness datasets and associated reader code, and you will evaluate $M$ (no additional training or tuning allowed!) on those new datasets. Systems that enter will receive the additional homework point, and systems that achieve the top score will receive an additional 0.5 points.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Set-up">Set-up<a class="anchor-link" href="#Set-up">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">spearmanr</span>
<span class="kn">import</span> <span class="nn">vsm</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">VSM_HOME</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;vsmdata&#39;</span><span class="p">)</span>

<span class="n">WORDSIM_HOME</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;wordsim&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dataset-readers">Dataset readers<a class="anchor-link" href="#Dataset-readers">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">wordsim_dataset_reader</span><span class="p">(</span>
        <span class="n">src_filename</span><span class="p">,</span>
        <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span>
        <span class="n">score_col_index</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Basic reader that works for all similarity datasets. They are</span>
<span class="sd">    all tabular-style releases where the first two columns give the</span>
<span class="sd">    word and a later column (`score_col_index`) gives the score.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    src_filename : str</span>
<span class="sd">        Full path to the source file.</span>

<span class="sd">    header : bool</span>
<span class="sd">        Whether `src_filename` has a header.</span>

<span class="sd">    delimiter : str</span>
<span class="sd">        Field delimiter in `src_filename`.</span>

<span class="sd">    score_col_index : int</span>
<span class="sd">        Column containing the similarity scores Default: 2</span>

<span class="sd">    Yields</span>
<span class="sd">    ------</span>
<span class="sd">    (str, str, float)</span>
<span class="sd">       (w1, w2, score) where `score` is the negative of the similarity</span>
<span class="sd">       score in the file so that we are intuitively aligned with our</span>
<span class="sd">       distance-based code. To align with our VSMs, all the words are</span>
<span class="sd">       downcased.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">src_filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="n">delimiter</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">header</span><span class="p">:</span>
            <span class="nb">next</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
            <span class="n">w1</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="n">w2</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="n">score_col_index</span><span class="p">]</span>
            <span class="c1"># Negative of scores to align intuitively with distance functions:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
            <span class="k">yield</span> <span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">wordsim353_reader</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;WordSim-353: http://www.gabrilovich.com/resources/data/wordsim353/&quot;&quot;&quot;</span>
    <span class="n">src_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">WORDSIM_HOME</span><span class="p">,</span> <span class="s1">&#39;wordsim353&#39;</span><span class="p">,</span> <span class="s1">&#39;combined.csv&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wordsim_dataset_reader</span><span class="p">(</span>
        <span class="n">src_filename</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">mturk771_reader</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;MTURK-771: http://www2.mta.ac.il/~gideon/mturk771.html&quot;&quot;&quot;</span>
    <span class="n">src_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">WORDSIM_HOME</span><span class="p">,</span> <span class="s1">&#39;MTURK-771.csv&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wordsim_dataset_reader</span><span class="p">(</span>
        <span class="n">src_filename</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">simverb3500dev_reader</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;SimVerb-3500: https://www.aclweb.org/anthology/D16-1235/&quot;&quot;&quot;</span>
    <span class="n">src_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">WORDSIM_HOME</span><span class="p">,</span> <span class="s1">&#39;SimVerb-3500&#39;</span><span class="p">,</span> <span class="s1">&#39;SimVerb-500-dev.txt&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wordsim_dataset_reader</span><span class="p">(</span>
        <span class="n">src_filename</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">score_col_index</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">simverb3500test_reader</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;SimVerb-3500: https://www.aclweb.org/anthology/D16-1235/&quot;&quot;&quot;</span>
    <span class="n">src_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">WORDSIM_HOME</span><span class="p">,</span> <span class="s1">&#39;SimVerb-3500&#39;</span><span class="p">,</span> <span class="s1">&#39;SimVerb-3000-test.txt&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wordsim_dataset_reader</span><span class="p">(</span>
        <span class="n">src_filename</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">score_col_index</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">men_reader</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;MEN: https://staff.fnwi.uva.nl/e.bruni/MEN&quot;&quot;&quot;</span>
    <span class="n">src_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">WORDSIM_HOME</span><span class="p">,</span> <span class="s1">&#39;MEN&#39;</span><span class="p">,</span> <span class="s1">&#39;MEN_dataset_natural_form_full&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wordsim_dataset_reader</span><span class="p">(</span>
        <span class="n">src_filename</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This collection of readers will be useful for flexible evaluations:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">READERS</span> <span class="o">=</span> <span class="p">(</span><span class="n">wordsim353_reader</span><span class="p">,</span> <span class="n">mturk771_reader</span><span class="p">,</span> <span class="n">simverb3500dev_reader</span><span class="p">,</span>
           <span class="n">simverb3500test_reader</span><span class="p">,</span> <span class="n">men_reader</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dataset-comparisons">Dataset comparisons<a class="anchor-link" href="#Dataset-comparisons">&#182;</a></h2><p>This section does some basic analysis of the datasets. The goal is to obtain a deeper understanding of what problem we're solving – what strengths and weaknesses the datasets have and how they relate to each other. For a full-fledged project, we would want to continue work like this and report on it in the paper, to provide context for the results.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_reader_name</span><span class="p">(</span><span class="n">reader</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a cleaned-up name for the dataset iterator `reader`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">reader</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;_reader&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Vocab-overlap">Vocab overlap<a class="anchor-link" href="#Vocab-overlap">&#182;</a></h3><p>How many vocabulary items are shared across the datasets?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_reader_vocab</span><span class="p">(</span><span class="n">reader</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return the set of words (str) in `reader`.&quot;&quot;&quot;</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">():</span>
        <span class="n">vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">w1</span><span class="p">)</span>
        <span class="n">vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">w2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">vocab</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_reader_vocab_overlap</span><span class="p">(</span><span class="n">readers</span><span class="o">=</span><span class="n">READERS</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get data on the vocab-level relationships between pairs of</span>
<span class="sd">    readers. Returns a a pd.DataFrame containing this information.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">r1</span><span class="p">,</span> <span class="n">r2</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">readers</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">v1</span> <span class="o">=</span> <span class="n">get_reader_vocab</span><span class="p">(</span><span class="n">r1</span><span class="p">)</span>
        <span class="n">v2</span> <span class="o">=</span> <span class="n">get_reader_vocab</span><span class="p">(</span><span class="n">r2</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;d1&#39;</span><span class="p">:</span> <span class="n">get_reader_name</span><span class="p">(</span><span class="n">r1</span><span class="p">),</span>
            <span class="s1">&#39;d2&#39;</span><span class="p">:</span> <span class="n">get_reader_name</span><span class="p">(</span><span class="n">r2</span><span class="p">),</span>
            <span class="s1">&#39;overlap&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">v1</span> <span class="o">&amp;</span> <span class="n">v2</span><span class="p">),</span>
            <span class="s1">&#39;union&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">v1</span> <span class="o">|</span> <span class="n">v2</span><span class="p">),</span>
            <span class="s1">&#39;d1_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">v1</span><span class="p">),</span>
            <span class="s1">&#39;d2_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">v2</span><span class="p">)}</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab_overlap</span> <span class="o">=</span> <span class="n">get_reader_vocab_overlap</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">vocab_overlap_crosstab</span><span class="p">(</span><span class="n">vocab_overlap</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return an intuitively formatted `pd.DataFrame` giving vocab-overlap</span>
<span class="sd">    counts for all the datasets represented in `vocab_overlap`, the</span>
<span class="sd">    output of `get_reader_vocab_overlap`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">xtab</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span>
        <span class="n">vocab_overlap</span><span class="p">[</span><span class="s1">&#39;d1&#39;</span><span class="p">],</span>
        <span class="n">vocab_overlap</span><span class="p">[</span><span class="s1">&#39;d2&#39;</span><span class="p">],</span>
        <span class="n">values</span><span class="o">=</span><span class="n">vocab_overlap</span><span class="p">[</span><span class="s1">&#39;overlap&#39;</span><span class="p">],</span>
        <span class="n">aggfunc</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>
    <span class="c1"># Blank out the upper right to reduce visual clutter:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">xtab</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">xtab</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">xtab</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">return</span> <span class="n">xtab</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab_overlap_crosstab</span><span class="p">(</span><span class="n">vocab_overlap</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This looks reasonable. By design, the SimVerb dev and test sets have a lot of overlap. The other overlap numbers are pretty small, even adjusting for dataset size.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Pair-overlap-and-score-correlations">Pair overlap and score correlations<a class="anchor-link" href="#Pair-overlap-and-score-correlations">&#182;</a></h3><p>How many word pairs are shared across datasets and, for shared pairs, what is the correlation between their scores? That is, do the datasets agree?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_reader_pairs</span><span class="p">(</span><span class="n">reader</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the set of alphabetically-sorted word (str) tuples</span>
<span class="sd">    in `reader`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">sorted</span><span class="p">([</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">])):</span> <span class="n">score</span> <span class="k">for</span> <span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">()}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_reader_pair_overlap</span><span class="p">(</span><span class="n">readers</span><span class="o">=</span><span class="n">READERS</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a `pd.DataFrame` giving the number of overlapping</span>
<span class="sd">    word-pairs in pairs of readers, along with the Spearman</span>
<span class="sd">    correlations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">r1</span><span class="p">,</span> <span class="n">r2</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">READERS</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">r1</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="n">r2</span><span class="o">.</span><span class="vm">__name__</span><span class="p">:</span>
            <span class="n">d1</span> <span class="o">=</span> <span class="n">get_reader_pairs</span><span class="p">(</span><span class="n">r1</span><span class="p">)</span>
            <span class="n">d2</span> <span class="o">=</span> <span class="n">get_reader_pairs</span><span class="p">(</span><span class="n">r2</span><span class="p">)</span>
            <span class="n">overlap</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">d1</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">d2</span><span class="p">:</span>
                    <span class="n">overlap</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">s</span><span class="p">,</span> <span class="n">d2</span><span class="p">[</span><span class="n">p</span><span class="p">]])</span>
            <span class="k">if</span> <span class="n">overlap</span><span class="p">:</span>
                <span class="n">s1</span><span class="p">,</span> <span class="n">s2</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">overlap</span><span class="p">)</span>
                <span class="n">rho</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">rho</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="c1"># Canonical order for the pair:</span>
            <span class="n">n1</span><span class="p">,</span> <span class="n">n2</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">get_reader_name</span><span class="p">(</span><span class="n">r1</span><span class="p">),</span> <span class="n">get_reader_name</span><span class="p">(</span><span class="n">r2</span><span class="p">)])</span>
            <span class="n">d</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;d1&#39;</span><span class="p">:</span> <span class="n">n1</span><span class="p">,</span>
                <span class="s1">&#39;d2&#39;</span><span class="p">:</span> <span class="n">n2</span><span class="p">,</span>
                <span class="s1">&#39;pair_overlap&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">overlap</span><span class="p">),</span>
                <span class="s1">&#39;rho&#39;</span><span class="p">:</span> <span class="n">rho</span><span class="p">}</span>
            <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s1">&#39;pair_overlap&#39;</span><span class="p">,</span><span class="s1">&#39;d1&#39;</span><span class="p">,</span><span class="s1">&#39;d2&#39;</span><span class="p">],</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># Return only every other row to avoid repeats:</span>
    <span class="k">return</span> <span class="n">df</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="s1">&#39;IS_GRADESCOPE_ENV&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="n">display</span><span class="p">(</span><span class="n">get_reader_pair_overlap</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This looks reasonable: none of the datasets have a lot of overlapping pairs, so we don't have to worry too much about places where they give conflicting scores.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation">Evaluation<a class="anchor-link" href="#Evaluation">&#182;</a></h2><p>This section builds up the evaluation code that you'll use for the homework and bake-off. For illustrations, I'll read in a VSM created from <code>data/vsmdata/giga_window5-scaled.csv.gz</code>:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">giga5</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">VSM_HOME</span><span class="p">,</span> <span class="s2">&quot;giga_window5-scaled.csv.gz&quot;</span><span class="p">),</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Dataset-evaluation">Dataset evaluation<a class="anchor-link" href="#Dataset-evaluation">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">word_similarity_evaluation</span><span class="p">(</span><span class="n">reader</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">distfunc</span><span class="o">=</span><span class="n">vsm</span><span class="o">.</span><span class="n">cosine</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Word-similarity evalution framework.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reader : iterator</span>
<span class="sd">        A reader for a word-similarity dataset. Just has to yield</span>
<span class="sd">        tuples (word1, word2, score).</span>

<span class="sd">    df : pd.DataFrame</span>
<span class="sd">        The VSM being evaluated.</span>

<span class="sd">    distfunc : function mapping vector pairs to floats.</span>
<span class="sd">        The measure of distance between vectors. Can also be</span>
<span class="sd">        `vsm.euclidean`, `vsm.matching`, `vsm.jaccard`, as well as</span>
<span class="sd">        any other float-valued function on pairs of vectors.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If `df.index` is not a subset of the words in `reader`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float, data</span>
<span class="sd">        `float` is the Spearman rank correlation coefficient between</span>
<span class="sd">        the dataset scores and the similarity values obtained from</span>
<span class="sd">        `df` using  `distfunc`. This evaluation is sensitive only to</span>
<span class="sd">        rankings, not to absolute values.  `data` is a `pd.DataFrame`</span>
<span class="sd">        with columns[&#39;word1&#39;, &#39;word2&#39;, &#39;score&#39;, &#39;distance&#39;].</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">():</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;word1&#39;</span><span class="p">:</span> <span class="n">w1</span><span class="p">,</span> <span class="s1">&#39;word2&#39;</span><span class="p">:</span> <span class="n">w2</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="n">score</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="p">[</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Word &#39;</span><span class="si">{}</span><span class="s2">&#39; is in the similarity dataset </span><span class="si">{}</span><span class="s2"> but not in the &quot;</span>
                    <span class="s2">&quot;DataFrame, making this evaluation ill-defined. Please &quot;</span>
                    <span class="s2">&quot;switch to a DataFrame with an appropriate vocabulary.&quot;</span><span class="o">.</span>
                    <span class="nb">format</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">get_reader_name</span><span class="p">(</span><span class="n">reader</span><span class="p">)))</span>
        <span class="n">d</span><span class="p">[</span><span class="s1">&#39;distance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">distfunc</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">w1</span><span class="p">],</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">w2</span><span class="p">])</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">rho</span><span class="p">,</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;distance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rho</span><span class="p">,</span> <span class="n">data</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rho</span><span class="p">,</span> <span class="n">eval_df</span> <span class="o">=</span> <span class="n">word_similarity_evaluation</span><span class="p">(</span><span class="n">men_reader</span><span class="p">,</span> <span class="n">giga5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rho</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">eval_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Dataset-error-analysis">Dataset error analysis<a class="anchor-link" href="#Dataset-error-analysis">&#182;</a></h3><p>For error analysis, we can look at the words with the largest delta between the gold score and the distance value in our VSM. We do these comparisons based on ranks, just as with our primary metric (Spearman $\rho$), and we normalize both rankings so that they have a comparable number of levels.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">word_similarity_error_analysis</span><span class="p">(</span><span class="n">eval_df</span><span class="p">):</span>
    <span class="n">eval_df</span><span class="p">[</span><span class="s1">&#39;distance_rank&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_normalized_ranking</span><span class="p">(</span><span class="n">eval_df</span><span class="p">[</span><span class="s1">&#39;distance&#39;</span><span class="p">])</span>
    <span class="n">eval_df</span><span class="p">[</span><span class="s1">&#39;score_rank&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_normalized_ranking</span><span class="p">(</span><span class="n">eval_df</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">])</span>
    <span class="n">eval_df</span><span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">]</span> <span class="o">=</span>  <span class="nb">abs</span><span class="p">(</span><span class="n">eval_df</span><span class="p">[</span><span class="s1">&#39;distance_rank&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">eval_df</span><span class="p">[</span><span class="s1">&#39;score_rank&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">eval_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;error&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_normalized_ranking</span><span class="p">(</span><span class="n">series</span><span class="p">):</span>
    <span class="n">ranks</span> <span class="o">=</span> <span class="n">series</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;dense&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ranks</span> <span class="o">/</span> <span class="n">ranks</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Best predictions:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">word_similarity_error_analysis</span><span class="p">(</span><span class="n">eval_df</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Worst predictions:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">word_similarity_error_analysis</span><span class="p">(</span><span class="n">eval_df</span><span class="p">)</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Full-evaluation">Full evaluation<a class="anchor-link" href="#Full-evaluation">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A full evaluation is just a loop over all the readers on which one want to evaluate, with a macro-average at the end:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">full_word_similarity_evaluation</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">readers</span><span class="o">=</span><span class="n">READERS</span><span class="p">,</span> <span class="n">distfunc</span><span class="o">=</span><span class="n">vsm</span><span class="o">.</span><span class="n">cosine</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate a VSM against all datasets in `readers`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    df : pd.DataFrame</span>

<span class="sd">    readers : tuple</span>
<span class="sd">        The similarity dataset readers on which to evaluate.</span>

<span class="sd">    distfunc : function mapping vector pairs to floats.</span>
<span class="sd">        The measure of distance between vectors. Can also be</span>
<span class="sd">        `vsm.euclidean`, `vsm.matching`, `vsm.jaccard`, as well as</span>
<span class="sd">        any other float-valued function on pairs of vectors.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pd.Series</span>
<span class="sd">        Mapping dataset names to Spearman r values.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">reader</span> <span class="ow">in</span> <span class="n">readers</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">word_similarity_evaluation</span><span class="p">(</span><span class="n">reader</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">distfunc</span><span class="o">=</span><span class="n">distfunc</span><span class="p">)</span>
            <span class="n">scores</span><span class="p">[</span><span class="n">get_reader_name</span><span class="p">(</span><span class="n">reader</span><span class="p">)]</span> <span class="o">=</span> <span class="n">score</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="n">scores</span><span class="p">[</span><span class="n">get_reader_name</span><span class="p">(</span><span class="n">reader</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="n">series</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Spearman r&#39;</span><span class="p">)</span>
    <span class="n">series</span><span class="p">[</span><span class="s1">&#39;Macro-average&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">series</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">series</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="s1">&#39;IS_GRADESCOPE_ENV&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="n">display</span><span class="p">(</span><span class="n">full_word_similarity_evaluation</span><span class="p">(</span><span class="n">giga5</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Homework-questions">Homework questions<a class="anchor-link" href="#Homework-questions">&#182;</a></h2><p>Please embed your homework responses in this notebook, and do not delete any cells from the notebook. (You are free to add as many cells as you like as part of your responses.)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="PPMI-as-a-baseline-[0.5-points]">PPMI as a baseline [0.5 points]<a class="anchor-link" href="#PPMI-as-a-baseline-[0.5-points]">&#182;</a></h3><p>The insight behind PPMI is a recurring theme in word representation learning, so it is a natural baseline for our task. For this question, write a function called <code>run_giga_ppmi_baseline</code> that does the following:</p>
<ol>
<li><p>Reads the Gigaword count matrix with a window of 20 and a flat scaling function into a <code>pd.DataFrame</code>s, as is done in the VSM notebooks. The file is <code>data/vsmdata/giga_window20-flat.csv.gz</code>, and the VSM notebooks provide examples of the needed code.</p>
</li>
<li><p>Reweights this count matrix with PPMI.</p>
</li>
<li><p>Evaluates this reweighted matrix using <code>full_word_similarity_evaluation</code>. The return value of <code>run_giga_ppmi_baseline</code> should be the return value of this call to <code>full_word_similarity_evaluation</code>.</p>
</li>
</ol>
<p>The goal of this question is to help you get more familiar with the code in <code>vsm</code> and the function <code>full_word_similarity_evaluation</code>.</p>
<p>The function <code>test_run_giga_ppmi_baseline</code> can be used to test that you've implemented this specification correctly.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">run_giga_ppmi_baseline</span><span class="p">():</span>
    <span class="k">pass</span>
    <span class="c1">##### YOUR CODE HERE</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_run_giga_ppmi_baseline</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;`func` should be `run_giga_ppmi_baseline&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">func</span><span class="p">()</span>
    <span class="n">ws_result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;wordsim353&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ws_expected</span> <span class="o">=</span> <span class="mf">0.58</span>
    <span class="k">assert</span> <span class="n">ws_result</span> <span class="o">==</span> <span class="n">ws_expected</span><span class="p">,</span> \
        <span class="s2">&quot;Expected wordsim353 value of </span><span class="si">{}</span><span class="s2">; got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">ws_expected</span><span class="p">,</span> <span class="n">ws_result</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="s1">&#39;IS_GRADESCOPE_ENV&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="n">test_run_giga_ppmi_baseline</span><span class="p">(</span><span class="n">run_giga_ppmi_baseline</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Gigaword-with-LSA-at-different-dimensions-[0.5-points]">Gigaword with LSA at different dimensions [0.5 points]<a class="anchor-link" href="#Gigaword-with-LSA-at-different-dimensions-[0.5-points]">&#182;</a></h3><p>We might expect PPMI and LSA to form a solid pipeline that combines the strengths of PPMI with those of dimensionality reduction. However, LSA has a hyper-parameter $k$ – the dimensionality of the final representations – that will impact performance. For this problem, write a wrapper function <code>run_ppmi_lsa_pipeline</code> that does the following:</p>
<ol>
<li>Takes as input a count <code>pd.DataFrame</code> and an LSA parameter <code>k</code>.</li>
<li>Reweights the count matrix with PPMI.</li>
<li>Applies LSA with dimensionality <code>k</code>.</li>
<li>Evaluates this reweighted matrix using <code>full_word_similarity_evaluation</code>. The return value of <code>run_ppmi_lsa_pipeline</code> should be the return value of this call to <code>full_word_similarity_evaluation</code>.</li>
</ol>
<p>The goal of this question is to help you get a feel for how much LSA alone can contribute to this problem.</p>
<p>The  function <code>test_run_ppmi_lsa_pipeline</code> will test your function on the count matrix in <code>data/vsmdata/giga_window20-flat.csv.gz</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">run_ppmi_lsa_pipeline</span><span class="p">(</span><span class="n">count_df</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="k">pass</span>
    <span class="c1">##### YOUR CODE HERE</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_run_ppmi_lsa_pipeline</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;`func` should be `run_ppmi_lsa_pipeline`&quot;&quot;&quot;</span>
    <span class="n">giga20</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">VSM_HOME</span><span class="p">,</span> <span class="s2">&quot;giga_window20-flat.csv.gz&quot;</span><span class="p">),</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">giga20</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">men_expected</span> <span class="o">=</span> <span class="mf">0.57</span>
    <span class="n">men_result</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;men&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">men_result</span> <span class="o">==</span> <span class="n">men_expected</span><span class="p">,</span>\
        <span class="s2">&quot;Expected men value of </span><span class="si">{}</span><span class="s2">; got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">men_expected</span><span class="p">,</span> <span class="n">men_result</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="s1">&#39;IS_GRADESCOPE_ENV&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="n">test_run_ppmi_lsa_pipeline</span><span class="p">(</span><span class="n">run_ppmi_lsa_pipeline</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Gigaword-with-GloVe-[0.5-points]">Gigaword with GloVe [0.5 points]<a class="anchor-link" href="#Gigaword-with-GloVe-[0.5-points]">&#182;</a></h3><p>Can GloVe improve over the PPMI-based baselines we explored above? To begin to address this question, let's run GloVe and see how performance on our task changes throughout the optimization process.</p>
<p><strong>Your task</strong>: write a function <code>run_glove_wordsim_evals</code> that does the following:</p>
<ol>
<li><p>Has a parameter <code>n_runs</code> with default value <code>5</code>.</p>
</li>
<li><p>Reads in <code>data/vsmdata/giga_window5-scaled.csv.gz</code>.</p>
</li>
<li><p>Creates a <code>TorchGloVe</code> instance with <code>warm_start=True</code>, <code>max_iter=50</code>, and all other parameters set to their defaults.</p>
</li>
<li><p><code>n_runs</code> times, calls <code>fit</code> on your model and, after each, runs <code>full_word_similarity_evaluation</code> with default keyword parameters, extract the 'Macro-average' score, and add that score to a list.</p>
</li>
<li><p>Returns the list of scores created.</p>
</li>
</ol>
<p>The trend should give you a sense for whether it is worth running GloVe for more iterations.</p>
<p>Some implementation notes:</p>
<ul>
<li><p><code>TorchGloVe</code> will accept and return <code>pd.DataFrame</code> instances, so you shouldn't need to do any type conversions.</p>
</li>
<li><p>Performance will vary a lot for this function, so there is some uncertainty in the testing, but <code>run_glove_wordsim_evals</code> will at least check that you wrote a function with the right general logic.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">run_glove_wordsim_evals</span><span class="p">(</span><span class="n">n_runs</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>

    <span class="kn">from</span> <span class="nn">torch_glove</span> <span class="kn">import</span> <span class="n">TorchGloVe</span>

    <span class="c1">##### YOUR CODE HERE</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_run_small_glove_evals</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;`data` should be the return value of `run_glove_wordsim_evals`&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">),</span> \
        <span class="s2">&quot;`run_glove_wordsim_evals` should return a list&quot;</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="p">),</span> \
        <span class="p">(</span><span class="s2">&quot;All the values in the list returned by `run_glove_wordsim_evals` &quot;</span>
         <span class="s2">&quot;should be floats.&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="s1">&#39;IS_GRADESCOPE_ENV&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="n">glove_scores</span> <span class="o">=</span> <span class="n">run_glove_wordsim_evals</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">glove_scores</span><span class="p">)</span>
    <span class="n">test_run_small_glove_evals</span><span class="p">(</span><span class="n">glove_scores</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Dice-coefficient-[0.5-points]">Dice coefficient [0.5 points]<a class="anchor-link" href="#Dice-coefficient-[0.5-points]">&#182;</a></h3><p>Implement the Dice coefficient for real-valued vectors, as</p>
$$
\textbf{dice}(u, v) = 
1 - \frac{
  2 \sum_{i=1}^{n}\min(u_{i}, v_{i})
}{
    \sum_{i=1}^{n} u_{i} + v_{i}
}$$<p>You can use <code>test_dice_implementation</code> below to check that your implementation is correct.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">dice</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="k">pass</span>
    <span class="c1">##### YOUR CODE HERE</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_dice_implementation</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;`func` should be an implementation of `dice` as defined above.&quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[</span>  <span class="mf">4.</span><span class="p">,</span>   <span class="mf">4.</span><span class="p">,</span>   <span class="mf">2.</span><span class="p">,</span>   <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span>  <span class="mf">4.</span><span class="p">,</span>  <span class="mf">61.</span><span class="p">,</span>   <span class="mf">8.</span><span class="p">,</span>  <span class="mf">18.</span><span class="p">],</span>
        <span class="p">[</span>  <span class="mf">2.</span><span class="p">,</span>   <span class="mf">8.</span><span class="p">,</span>  <span class="mf">10.</span><span class="p">,</span>   <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">18.</span><span class="p">,</span>   <span class="mf">0.</span><span class="p">,</span>   <span class="mf">5.</span><span class="p">]])</span>
    <span class="k">assert</span> <span class="n">func</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">==</span> <span class="mf">0.80198</span>
    <span class="k">assert</span> <span class="n">func</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">==</span> <span class="mf">0.67568</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="s1">&#39;IS_GRADESCOPE_ENV&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="n">test_dice_implementation</span><span class="p">(</span><span class="n">dice</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="t-test-reweighting-[2-points]">t-test reweighting [2 points]<a class="anchor-link" href="#t-test-reweighting-[2-points]">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The t-test statistic can be thought of as a reweighting scheme. For a count matrix $X$, row index $i$, and column index $j$:</p>
$$\textbf{ttest}(X, i, j) = 
\frac{
    P(X, i, j) - \big(P(X, i, *)P(X, *, j)\big)
}{
\sqrt{(P(X, i, *)P(X, *, j))}
}$$<p>where $P(X, i, j)$ is $X_{ij}$ divided by the total values in $X$, $P(X, i, *)$ is the sum of the values in row $i$ of $X$ divided by the total values in $X$, and $P(X, *, j)$ is the sum of the values in column $j$ of $X$ divided by the total values in $X$.</p>
<p>For this problem, implement this reweighting scheme. You can use <code>test_ttest_implementation</code> below to check that your implementation is correct. You do not need to use this for any evaluations, though we hope you will be curious enough to do so!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">ttest</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="k">pass</span>
    <span class="c1">##### YOUR CODE HERE</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_ttest_implementation</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;`func` should be `ttest`&quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[</span>  <span class="mf">4.</span><span class="p">,</span>   <span class="mf">4.</span><span class="p">,</span>   <span class="mf">2.</span><span class="p">,</span>   <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span>  <span class="mf">4.</span><span class="p">,</span>  <span class="mf">61.</span><span class="p">,</span>   <span class="mf">8.</span><span class="p">,</span>  <span class="mf">18.</span><span class="p">],</span>
        <span class="p">[</span>  <span class="mf">2.</span><span class="p">,</span>   <span class="mf">8.</span><span class="p">,</span>  <span class="mf">10.</span><span class="p">,</span>   <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">18.</span><span class="p">,</span>   <span class="mf">0.</span><span class="p">,</span>   <span class="mf">5.</span><span class="p">]]))</span>
    <span class="n">actual</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[</span> <span class="mf">0.33056</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.07689</span><span class="p">,</span>  <span class="mf">0.04321</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.10532</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.07689</span><span class="p">,</span>  <span class="mf">0.03839</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.10874</span><span class="p">,</span>  <span class="mf">0.07574</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.04321</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.10874</span><span class="p">,</span>  <span class="mf">0.36111</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14894</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.10532</span><span class="p">,</span>  <span class="mf">0.07574</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14894</span><span class="p">,</span>  <span class="mf">0.05767</span><span class="p">]])</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">predicted</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">actual</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="s1">&#39;IS_GRADESCOPE_ENV&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="n">test_ttest_implementation</span><span class="p">(</span><span class="n">ttest</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Enriching-a-VSM-with-subword-information-[2-points]">Enriching a VSM with subword information [2 points]<a class="anchor-link" href="#Enriching-a-VSM-with-subword-information-[2-points]">&#182;</a></h3><p>It might be useful to combine character-level information with word-level information. To help you begin asssessing this idea, this question asks you to write a function that modifies an existing VSM so that the representation for each word $w$ is the element-wise sum of $w$'s original word-level representation with all the representations for the n-grams $w$ contains.</p>
<p>The following starter code should help you structure this and clarify the requirements, and a simple test is included below as well.</p>
<p>You don't need to write a lot of code; the motivation for this question is that the function you write could have practical value.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">subword_enrichment</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">pass</span>
    <span class="c1"># 1. Use `vsm.ngram_vsm` to create a character-level</span>
    <span class="c1"># VSM from `df`, using the above parameter `n` to</span>
    <span class="c1"># set the size of the ngrams.</span>

    <span class="c1">##### YOUR CODE HERE</span>


    <span class="c1"># 2. Use `vsm.character_level_rep` to get the representation</span>
    <span class="c1"># for every word in `df` according to the character-level</span>
    <span class="c1"># VSM you created above.</span>

    <span class="c1">##### YOUR CODE HERE</span>


    <span class="c1"># 3. For each representation created at step 2, add in its</span>
    <span class="c1"># original representation from `df`. (This should use</span>
    <span class="c1"># element-wise addition; the dimensionality of the vectors</span>
    <span class="c1"># will be unchanged.)</span>

    <span class="c1">##### YOUR CODE HERE</span>


    <span class="c1"># 4. Return a `pd.DataFrame` with the same index and column</span>
    <span class="c1"># values as `df`, but filled with the new representations</span>
    <span class="c1"># created at step 3.</span>

    <span class="c1">##### YOUR CODE HERE</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test_subword_enrichment</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;`func` should be an implementation of subword_enrichment as</span>
<span class="sd">    defined above.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ABCD&quot;</span><span class="p">,</span> <span class="s2">&quot;BCDA&quot;</span><span class="p">,</span> <span class="s2">&quot;CDAB&quot;</span><span class="p">,</span> <span class="s2">&quot;DABC&quot;</span><span class="p">]</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">index</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
    <span class="n">expected</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span>
        <span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">14</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">22</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">26</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]],</span> <span class="n">index</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
    <span class="n">new_df</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">expected</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">new_df</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span> \
        <span class="s2">&quot;Columns are not the same&quot;</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">expected</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">new_df</span><span class="o">.</span><span class="n">index</span><span class="p">),</span> \
        <span class="s2">&quot;Indices are not the same&quot;</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">expected</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">new_df</span><span class="o">.</span><span class="n">values</span><span class="p">),</span> \
        <span class="s2">&quot;Co-occurrence values aren&#39;t the same&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="s1">&#39;IS_GRADESCOPE_ENV&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="n">test_subword_enrichment</span><span class="p">(</span><span class="n">subword_enrichment</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Your-original-system-[3-points]">Your original system [3 points]<a class="anchor-link" href="#Your-original-system-[3-points]">&#182;</a></h3><p>This question asks you to design your own model. You can of course include steps made above (ideally, the above questions informed your system design!), but your model should not be literally identical to any of the above models. Other ideas: retrofitting, autoencoders, GloVe, subword modeling, ...</p>
<p>Requirements:</p>
<ol>
<li><p>Your code must operate on one or more of the count matrices in <code>data/vsmdata</code>. You can choose which subset of them; this is an important design feature of your system. <strong>Other pretrained vectors cannot be introduced</strong>.</p>
</li>
<li><p>Retrofitting is permitted.</p>
</li>
<li><p>Your code must be self-contained, so that we can work with your model directly in your homework submission notebook. If your model depends on external data or other resources, please submit a ZIP archive containing these resources along with your submission.</p>
</li>
</ol>
<p>In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies. We also ask that you report the best score your system got during development, just to help us understand how systems performed overall.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:</span>
<span class="c1">#   1) Textual description of your system.</span>
<span class="c1">#   2) The code for your original system.</span>
<span class="c1">#   3) The score achieved by your system in place of MY_NUMBER.</span>
<span class="c1">#        With no other changes to that line.</span>
<span class="c1">#        You should report your score as a decimal value &lt;=1.0</span>
<span class="c1"># PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS</span>

<span class="c1"># NOTE: MODULES, CODE AND DATASETS REQUIRED FOR YOUR ORIGINAL SYSTEM </span>
<span class="c1"># SHOULD BE ADDED BELOW THE &#39;IS_GRADESCOPE_ENV&#39; CHECK CONDITION. DOING</span>
<span class="c1"># SO ABOVE THE CHECK MAY CAUSE THE AUTOGRADER TO FAIL.</span>

<span class="c1"># START COMMENT: Enter your system description in this cell.</span>
<span class="c1"># My peak score was: MY_NUMBER</span>
<span class="k">if</span> <span class="s1">&#39;IS_GRADESCOPE_ENV&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="c1"># STOP COMMENT: Please do not remove this comment.</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Bake-off-[1-point]">Bake-off [1 point]<a class="anchor-link" href="#Bake-off-[1-point]">&#182;</a></h2><p>For the bake-off, we will release two additional datasets. The announcement will go out on the discussion forum. We will also release reader code for these datasets that you can paste into this notebook. You will evaluate your custom model $M$ (from the previous question) on these new datasets using <code>full_word_similarity_evaluation</code>. Rules:</p>
<ol>
<li>Only one evaluation is permitted.</li>
<li>No additional system tuning is permitted once the bake-off has started.</li>
</ol>
<p>The cells below this one constitute your bake-off entry.</p>
<p>People who enter will receive the additional homework point, and people whose systems achieve the top score will receive an additional 0.5 points. We will test the top-performing systems ourselves, and only systems for which we can reproduce the reported results will win the extra 0.5 points.</p>
<p>Late entries will be accepted, but they cannot earn the extra 0.5 points. Similarly, you cannot win the bake-off unless your homework is submitted on time.</p>
<p>The announcement will include the details on where to submit your entry.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Enter your bake-off assessment code into this cell.</span>
<span class="c1"># Please do not remove this comment.</span>
<span class="k">if</span> <span class="s1">&#39;IS_GRADESCOPE_ENV&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="k">pass</span>
    <span class="c1"># Please enter your code in the scope of the above conditional.</span>
    <span class="c1">##### YOUR CODE HERE</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># On an otherwise blank line in this cell, please enter</span>
<span class="c1"># your &quot;Macro-average&quot; value as reported by the code above.</span>
<span class="c1"># Please enter only a number between 0 and 1 inclusive.</span>
<span class="c1"># Please do not remove this comment.</span>
<span class="k">if</span> <span class="s1">&#39;IS_GRADESCOPE_ENV&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="k">pass</span>
    <span class="c1"># Please enter your score in the scope of the above conditional.</span>
    <span class="c1">##### YOUR CODE HERE</span>
</pre></div>

    </div>
</div>
</div>

</div>
 


    </div>
  </div>

  </div>


  
    <footer class="footer hidden-print">
      <div class="container">
        <div class="col-md-4">
          <p>
            This website does not host notebooks, it only renders notebooks
            available on other websites.
          </p>
        </div>

        <div class="col-md-4">
          <p>
            Delivered by <a href="https://www.fastly.com/">Fastly</a>,
            Rendered by <a href="https://ovhcloud.com">OVHcloud</a>
          </p>
          <p>
            nbviewer GitHub <a href="https://github.com/jupyter/nbviewer">repository</a>.
          </p>
        </div>

        <div class="col-md-4">
          
  
            
              <p>
                nbviewer version:
                <a href="https://github.com/jupyter/nbviewer/commit/90c61ccda0e4ae08ce46511c45505b49663fb019">
                  90c61cc
                </a>
              </p>
            
          
  
  <p>
    nbconvert version: <a href="https://github.com/jupyter/nbconvert/releases/tag/5.6.1">
      5.6.1
    </a>
  </p>
  

          
  
  
  <p>
    Rendered
    <span class='date' data-date='Tue, 19 Jan 2021 20:30:32 UTC' title='Tue, 19 Jan 2021 20:30:32 UTC'>(Tue, 19 Jan 2021 20:30:32 UTC)</span>
  </p>
  

        </div>
      </div>
    </footer>
  

  <script src="/static/components/bootstrap/js/bootstrap.min.js"></script>
  <script src="/static/components/headroom.js/dist/headroom.min.js"></script>
  <script src="/static/components/headroom.js/dist/jQuery.headroom.min.js"></script>

  
  
  <script>
    $(function(){ $("#menubar").headroom({
      tolerance: 5,
      offset: 205,
      classes: {
        initial: "animated",
        pinned: "slideInDown",
        unpinned: "slideOutUp"
      }
    })});
  </script>


  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-52617120-5', 'auto',
       {'storage': 'none'});
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
  </script>
  
  <script>
    require({
        paths: {
          moment: "/static/components/moment/min/moment.min.js"
        }
      }, ["moment"], function(moment){
      var date = $("footer .date"),
        m = moment(new Date(date.data('date'))),
        update = function(){ date.text(m.fromNow()); };
      setInterval(update, 61*1000);
      update();
      var w = $(window).scroll(function(event){
        $("body").toggleClass("scrolled", w.scrollTop() > 0);
      });
    });
  </script>

  <!--NEW RELIC Stop Perf Measurement-->
  
  <!--NEW RELIC End-->
</body>
</html>